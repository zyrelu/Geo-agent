{
  "0": "Robust, metadata-driven, masked, reproducible EO thermal analysis, LST pipeline, and TVDI hotspot workflow:\n- Inventory inputs and metadata; manage paths explicitly and pass saved file paths between steps. Read sensor/product MTL/metadata to audit radiometry and units: record whether thermal inputs are DN, radiance, brightness temperature (BT), or LST; capture RADIANCE_MULT/ADD (ML/AL) or equivalent rescaling coefficients, K1/K2 Planck constants, thermal band center wavelength, surface reflectance scale factors, and tool/model versions. Verify required bands exist for the date/AOI. For Landsat L8/9: thermal Band 10, red/NIR surface reflectance (Bands 4/5), QA_PIXEL/QA band, CRS and pixel size.\n- Define the AOI (urban boundary plus surroundings) and clip all rasters to it.\n- Harmonize and co-register: ensure NDVI and LST share the same CRS, resolution, and grid; snap/resample as needed; verify alignment via overlay checks.\n- Equal-area handling for area-weighted proportions: if computing area-weighted ratios or comparing across latitudes, either reproject LST and valid_mask to an equal-area CRS (e.g., EPSG:6933) before counting/aggregating, or compute per-pixel geodesic areas and use them as weights. Log the choice and parameters.\n- Build a valid analysis mask: decode QA_PIXEL/QA bits to exclude clouds, cloud shadows, snow/ice; exclude water using QA water bits or a conservative NDWI threshold; remove NoData; combine to a single valid_mask used in all steps. Document bit codes and any NDWI thresholds used.\n- Metadata-driven units/scaling checks and conversions: do not assume Kelvin. If inputs are DN, convert DN→radiance via radiance = ML × DN + AL using MTL coefficients; if radiance, convert to BT using sensor K1/K2; confirm BT is in Kelvin. Confirm surface reflectance scaling to [0–1] using provided scale factors and avoid double-scaling. Record all constants and formulas used.\n- Compute NDVI on valid pixels. Use NDVI both to derive emissivity and to define optional thematic sub-masks (document thresholds), e.g., forest_mask = NDVI > 0.7 and non_vegetated_mask = NDVI < 0.2, applied within valid_mask.\n- NDVI-based emissivity: derive emissivity using Pv = ((NDVI − NDVImin)/(NDVImax − NDVImin))^2 (clip 0–1) and an emissivity rule (e.g., ε = 0.986 + 0.004·Pv for vegetation or a mixed-pixel formulation); alternatively use land-cover-based emissivity libraries. Document the choice and parameters.\n- Single-channel LST: compute LST using BT and emissivity with sensor-specific constants (e.g., LST = BT / [1 + (λ·BT/c2)·ln(ε)], λ ≈ 10.895 µm for L8 Band 10, c2 ≈ 1.438×10⁻² m·K). Output LST in Kelvin and keep invalid values masked. Validate units and plausible temperature ranges; inspect summary stats and histograms.\n- Masked statistics and differences: compute summary statistics (e.g., count, mean, median, percentiles, and optionally a trimmed mean) for LST within valid_mask and within NDVI-derived sub-masks (e.g., forest vs non-vegetated). Where relevant, compute differences between masks (e.g., ΔLST = mean_forest − mean_nonvegetated) and/or between dates; report only over valid pixels.\n- Multi-date aggregation and clear-sky weighting: when aggregating across multiple scenes/dates, weight per-date statistics by valid pixel counts (or area) to account for differing clear-sky coverage; prefer robust aggregators (median or trimmed mean). Log the weighting scheme and valid coverage per date.\n- TVDI: derive NDVI-dependent wet/dry edges from the LST–NDVI scatter, compute TVDI, clip to 0–1, and verify expected distributions.\n- Threshold quantification (hot or cool): apply explicit thresholds (e.g., LST > 305 K, TVDI > t, or LST < 300 K for coolness) only within valid_mask. Report area proportion as ratio = count((threshold_true ∧ valid_mask)) / count(valid_mask); state clearly whether reporting a fraction [0–1] or percent. For area-weighted proportions, use the equal-area grid or per-pixel area weights: ratio = sum(area_i for i where (threshold_true ∧ valid_mask_i)) / sum(area_i for i where valid_mask_i). Document threshold values/direction and any area-weighting choice.\n- Plausibility checks: cross-check city-scale LST summaries against independent references (e.g., reanalysis/climatology such as ERA5 2 m temperature at overpass time, in-situ if available) for magnitude sanity; investigate large deviations (cloud contamination, unit mistakes, or emissivity assumptions). Ensure wetlands/water remain excluded to avoid bias and avoid applying optical-only tools to thermal products.\n- Interpretation: intersect thresholds/hotspots and per-mask results with urban land-cover/context layers to explain patterns; ensure wetlands/water remain excluded to avoid bias.\n- Reproducibility and sanity checks: write intermediates and log paths, parameters, MTL/metadata constants (ML/AL, K1/K2), QA bit masks, emissivity/NDVI parameters, thresholds, dates, weights, and software versions; inspect histograms and quick maps of valid_mask, NDVI sub-masks, LST, and threshold results (including below-threshold coolness where applicable); spot-check known hot/cool features and confirm plausible LST ranges.",
  "1": "Adopt a QC-aware staged, thresholded Earth observation scene classification workflow with taxonomy alignment and DEM/NDWI cross-validation:\n- Inventory inputs (programmatic file listing) and validate metadata; record classifier name, version, parameters, and confirm label taxonomy alignment (map model class names/codes to the required output taxonomy; document merges/splits/synonyms and the mapping table/version).\n- Run batch scene classification to obtain per-class probabilities/logits; parse outputs into a canonical schema (scene/id, class, score, top-k list).\n- Acceptance policy and thresholds: accept the top-1 prediction only if its confidence ≥ conf_threshold and, optionally, the margin (top1 − top2) ≥ margin_threshold. If confidence is low or confusing classes co-appear in the top-5 (e.g., Beach vs Desert/Pond/Resort; Lake/Pond vs Water/Marsh; Mountain/Hill vs Desert/BareLand/Forest), flag the scene as ambiguous and route to secondary checks. Log conf_threshold, margin_threshold, and the confusion-pair rules used.\n- Secondary checks with multi-source domain cues: use DEM-derived elevation/slope/ruggedness for terrain-related classes; apply water detection via NDWI (from surface reflectance) or RGB water masks; apply sand brightness/texture heuristics for Beach/Desert disambiguation; leverage context/texture features; parcel/object segmentation where applicable; spectral indices including NDVI; if available, multi-date NDVI/time-series consistency; or a second model/ensemble cross-check. Document inputs, thresholds, and decision rules for each cue.\n- Basic error handling: catch model failures or malformed outputs; allow one controlled retry with safe parameters; mark unresolved/uncertain cases explicitly when QC fails.\n- Counting discipline: only count classes after QC confirmation; maintain an explicit \"uncertain\"/\"unresolved\" flag for cases not cleared by QC.\n- Automation and output formatting: automate parsing and counting and map final counts to the required multiple-choice output format/spec to prevent formatting errors; adhere strictly to the required schema.\n- Reproducibility: log confidence/margin thresholds, top-k size, taxonomy mapping, auxiliary sources used (DEM/NDVI/NDWI products and versions), confusion-pair triggers, and decision rationale; write intermediates to disk for auditability.",
  "2": "Establish a disciplined, fail-safe measurement and detection pipeline for EO imagery:\n- Inventory and verify inputs: programmatically list files, construct full explicit paths, validate key metadata (CRS, GSD/resolution, bands), spatial extent/AOI area, and generate a quicklook to confirm context and scale. Record sensor/product, acquisition time, and any radiometric scale factors.\n- Structured run plan (hierarchical): run the domain-specific detector first with explicit, logged parameters (target class(es), confidence threshold, NMS settings, tiling/stride, max detections) and record model/version/seed. Allow one retry (tuned thresholds/tiling) if the first run fails or is unstable; log the change and outcome.\n- Fail-safe fallback: if the detector errors out, returns no/implausible detections, or fails QC after the retry, switch to a segmentation or classical CV fallback. Use thresholding, morphology, texture/context cues; count via connected-component labeling; apply morphological splitting for touching objects (e.g., watershed or distance-transform split).\n- Robust post-processing: normalize detector/segmenter/CV outputs to a canonical schema (id, class, score, centroid/geometry, bbox, area). Apply simple filters (score thresholding, min/max area, circularity/elongation, edge proximity) within the AOI and relevant domain masks; for aquatic targets, apply size/shape filters only within a water mask. Perform NMS/deduplication across tiles and enforce AOI/domain masks. Use explicit retry limits to prevent infinite loops.\n- Qualifier-based selection and geometry metrics: when an answer requires qualifiers like \"largest,\" \"longest,\" or cardinal-extreme choices such as \"westernmost/easternmost/northernmost/southernmost,\" compute these from the actual mask/polygon geometry, not just the detection bbox. Derive geometric metrics (area, perimeter/length, centroid_x/centroid_y, min_x/min_y, max_x/max_y) in an appropriate CRS. Prefer the polygon centroid over the bbox midpoint for coordinates. For cardinal directions, base west/east on longitude (e.g., WGS84 lon) rather than image pixel columns; do not assume \"west ≈ left\" unless the image is north-up and unrotated. If the working CRS is projected, convert to lon/lat or otherwise ensure correct cardinal interpretation. When asked to return a \"closest\" object to a reference point, compute geodesic or projected distances consistently, break ties deterministically, and then round/report coordinates to the requested precision with units stated.\n- Validation and cross-checks: generate a quick overlay of detections/segments on the source imagery for sanity checks and spot-check true/false positives. Cross-validate not only counts but also shapes/locations with an alternate method or tool (e.g., classical CV or a second model); record discrepancies, derive an uncertainty estimate (e.g., inter-method difference or bootstrap CI), and document resolutions before finalizing.\n- Comparability and normalization for region comparisons: before comparing regions, verify detector/model settings are identical and source imagery is comparable (resolution/GSD, radiometry, acquisition date/conditions). Compute and report densities (objects per unit area) within AOIs rather than relying on raw counts: density = count(valid detections) / AOI area (or valid_mask area). If pixel sizes or valid coverage differ, use area-aware weighting and report the valid area used. Document AOI area, valid_mask coverage, and any normalization applied.\n- Measurements: for localized targets, compute counts, areas, densities, and distances as needed. Derive pairwise pixel distances between centroids and convert to meters using the image’s GSD or geotransform—avoid heuristic guessing. Convert AOI area to consistent units (e.g., km²) and report density units explicitly (e.g., tanks per km²). Document all conversions and assumptions.\n- Output formatting and reproducibility: adhere strictly to the required output formatting/spec. Aggregate counts/densities as specified. Log parameters, thresholds, masks, retries, model/alternate method versions, uncertainty estimation approach, AOI areas, and software versions; write intermediates to disk for auditability.",
  "3": "Own the time axis and intercept in EO time-series regression:\n- Build a time-indexed inventory from filenames/metadata; parse and sort by year; explicitly record gaps (e.g., missing 2024) rather than assuming continuous coverage.\n- Explicitly define the regression time variable before fitting and center it on a declared reference year: choose base_year (e.g., 2013) and set x = year − base_year for all fits. Record base_year in outputs, plots, and tables. This yields an interpretable intercept equal to y at the baseline year, aligns with typical reporting formats, and avoids large, unintuitive intercepts or post-hoc conversions that can introduce errors.\n- If absolute years must be used for x, document the conversion to the baseline explicitly: with a (slope) and b (intercept) from x = year, the baseline value is y(base_year) = a · base_year + b. Prefer the centered approach to minimize conversion mistakes.\n- Document and propagate the chosen convention (time variable definition and base_year) in plots, tables, and comparisons so different implementations align; include it in metadata/logs for reproducibility.\n- Use only the actual available years in the regression and clearly call out which years are excluded.",
  "4": "Establish a disciplined, fail-safe measurement and detection pipeline for EO imagery:\n- Inventory ASTER TIR inputs and metadata: confirm product type (e.g., ASTER L1B TIR bands 10–14 or an LST+emissivity TES product), QA layers, scale factors, CRS, pixel size, and software/tool versions used to run TES.\n- Run TES or verify TES outputs: generate or validate per-pixel LST and emissivity layers; record whether emissivity is broadband or band-specific and its units (dimensionless), and confirm LST units (Kelvin).\n- Data lineage and band-specific validation: reuse the exact TES output path(s) and verify metadata (date, AOI, product/version) before any analysis. Explicitly select the intended emissivity band or the Δε layer (if provided or derived), and confirm expected value ranges (emissivity ~0.85–0.99; Δε ~0–0.3). This guards against analyzing the wrong variable (e.g., LST) or an incorrect band. Log the selected band/layer name/code and its expected range check.\n- Define and clip to the AOI: use the specified LA metro boundary; clip the TES LST/emissivity and QA rasters to the AOI.\n- Harmonize grids: ensure all rasters (LST, emissivity, QA/cloud/water masks, urban land-cover) share the same CRS, resolution, and grid; reproject/resample external masks to the TES grid; verify alignment with overlay checks.\n- Build a trusted urban mask: select urban/built-up classes from a vetted land-cover source (e.g., NLCD, ESA WorldCover, GHSL); reproject/resample to match TES LST/emissivity; document class codes used and resampling method.\n- Validity masking: decode and apply QA/cloud/water/NoData masks from ASTER/TES and the land-cover source; combine with the urban mask to form a valid_urban_mask used in all subsequent steps.\n- Thresholds and metric: compute the percentage (or fraction, stated explicitly) of valid urban pixels meeting both conditions LST > 300 K AND emissivity < 0.96. Use ratio = count((LST > 300 K ∧ emissivity < 0.96) ∧ valid_urban_mask) / count(valid_urban_mask). Optionally apply area weights if pixel areas vary.\n- Optional Δε-based proportion: for workflows requiring emissivity contrast checks, build Δε (e.g., band 12 minus band 10 emissivity, or a provided Δε layer), confirm its expected range, and compute the proportion of valid urban pixels with Δε > 0.05. Use ratio = count((Δε > 0.05) ∧ valid_urban_mask) / count(valid_urban_mask). Inspect histograms/statistics of Δε to validate distributions and thresholds.\n- Sanity checks: verify expected LST ranges and emissivity/Δε distributions over urban pixels; inspect quick-look maps of valid_urban_mask and threshold results; spot-check known hot/cool urban features.\n- Reproducibility: explicitly log paths (and reuse exact TES output paths), AOI definition, projections/resampling choices, TES parameters, emissivity layer selection (broadband vs band-specific) and any Δε construction, thresholds, dates, and software versions; write intermediates to disk for auditability.",
  "5": "Define and compute the right vegetation coverage metric for change analysis:\n- Inventory and harmonize inputs: list NDVI or surface reflectance products, QA/bitmask layers, AOI, CRS, pixel size, scale factors, acquisition dates, and software versions. Ensure all rasters are clipped to the AOI and share the same CRS, resolution, and grid; snap/resample as needed and verify alignment via overlay checks.\n- Convert NDVI to physical units: confirm whether NDVI is delivered scaled (e.g., int16 with scale factor) or computed from surface reflectance; apply the provided scale factors so NDVI falls in [−1, 1] and avoid double-scaling. If computing NDVI, use properly scaled red/NIR reflectance inputs.\n- Build a valid analysis mask: decode QA bits to exclude clouds, cloud shadows, snow/ice; exclude water/wetlands where vegetated coverage would be biased; remove NoData; combine to a single valid_mask used in all steps.\n- Compositing strategy: reduce noise and residual cloud impacts by compositing within consistent temporal windows (e.g., monthly median or best-of clear observations). Document the window, compositing statistic, and any per-pixel quality ranking used.\n- Vegetation coverage metric options (choose and document):\n  • Fractional Vegetation Cover (FVC) via NDVI endmembers: FVC = ((NDVI − NDVIsoil) / (NDVIveg − NDVIsoil)), clipped to [0, 1]. Select NDVIsoil and NDVIveg endmembers from literature or scene-specific distributions (e.g., soil ~0.05–0.15, dense vegetation ~0.7–0.9), and record the choice.\n  • Percent vegetated area above a threshold: define a vegetation NDVI or FVC threshold (e.g., NDVI ≥ 0.3 or FVC ≥ 0.5). Compute coverage as the proportion of valid_mask pixels meeting the threshold: ratio = count(threshold_true ∧ valid_mask) / count(valid_mask). State clearly whether reporting a fraction [0–1] or percent, and optionally weight by pixel area if it varies.\n- Per-date coverage: for each composited date, compute and store the chosen coverage metric over the AOI (or subregions). Keep invalid pixels masked and log counts of valid pixels.\n- Change analysis with guards: scan date pairs (prefer seasonally matched windows to reduce phenology confounds) to find the maximum percentage increase. Compute percent change as (coverage_t2 − coverage_t1) / max(coverage_t1, epsilon), with an explicit epsilon (e.g., 0.01) to guard against near-zero baselines. Consider also reporting absolute change and requiring coverage_t1 ≥ min_baseline to avoid inflated ratios. Document the chosen epsilon/min_baseline.\n- Reproducibility and sanity checks: log paths, dates, QA bit masks, endmembers, thresholds, compositing settings, and versions. Inspect histograms and quick maps of NDVI, FVC, valid_mask, and coverage thresholds; confirm plausible ranges and that water/clouds are excluded. Avoid using raw NDVI means or maxima as a proxy for coverage; they do not directly translate to area or fraction and can be biased by outliers.\n- Sensor and seasonal consistency: if combining sensors or years, ensure comparable NDVI scaling and similar seasonal windows; consider per-sensor endmembers or cross-sensor harmonization. Clearly report which dates are included and any gaps.",
  "6": "Validate, mask, and aggregate city–month summaries with cross-checks:\n- Inventory and grouping: programmatically list input files and explicitly group them by city and month; record grouping keys, city boundary sources/versions, and month definitions (calendar months or custom windows). Parse and validate metadata consistency across groups (sensor/product, units/scales, CRS, pixel size, software/tool versions).\n- Temporal completeness: build a time index per city; mark missing months explicitly rather than assuming continuity; decide and document whether to skip or impute missing months (and avoid implicit zeros).\n- AOI and validity masking: apply the city-boundary AOI to all rasters; decode and apply QA/cloud/water/NoData masks; exclude zeros used as NoData or fill values so they do not bias statistics; combine to a single valid_mask per city–month.\n- Harmonize grids: ensure all rasters used in summaries share the same CRS, resolution, and grid within each city; snap/resample as needed; verify alignment with overlay checks.\n- Per-month robust metrics: within each city–month over valid_mask, compute robust summary statistics (e.g., mean plus median and/or a trimmed mean such as 10%) to handle outliers; record the trimming proportion and any additional outlier filters.\n- Weighting and aggregation across months: when aggregating to multi-month windows (e.g., 3-month averages), weight by the count of valid pixels (or area if pixel sizes differ) per city–month; log the weighting scheme and valid counts.\n- Inter-city differences: compute differences between cities for matched months and for multi-month windows; report clearly whether differences use weighted or unweighted averages and ensure comparable masks/units.\n- Arithmetic cross-verification: cross-check that the difference of 3-month averages equals the average of monthly differences under the same weighting; if they diverge, diagnose expected causes (e.g., differing weights/valid counts per month) and document.\n- Sanity checks: inspect distributions and quick-look maps of valid_mask and per-month metrics; verify expected magnitudes and ranges; spot-check known features; confirm that excluded clouds/water/NoData do not leak into summaries.\n- Reproducibility: log paths, grouping keys (city, month), AOIs, projections/resampling choices, QA masks, weighting scheme, statistics computed, dates included/excluded, and software versions; write intermediate valid_mask counts and per-month metrics to disk for auditability.",
  "7": "Run a reproducible, QC-aware nighttime lights hotspot proportion change analysis over the LA ROI:\n- Inventory nighttime lights inputs and metadata: select one annual product and keep it consistent across years (e.g., VIIRS VNL V2 annual composite or NASA Black Marble annual composites). Record product name, version, year(s), radiometric units and scale factors, QA layers (e.g., stray light, ephemeral events/fire flags), CRS, pixel size, and software/tool versions. Verify both years use the exact same product/version to ensure radiometric comparability.\n- Define the ROI: use the LA boundary as the analysis region and clip all rasters to it.\n- Harmonize grids: ensure both annual NTL rasters share the same CRS, resolution, and grid; reproject/resample as needed and verify alignment via overlay checks.\n- Build a valid analysis mask: exclude NoData and water using provided QA/masks; apply any available QA flags to remove clouds/stray light/ephemeral events (e.g., fires) where applicable; combine to a single valid_mask used for all steps.\n- Units/scaling checks: confirm intensity units (e.g., nW·cm⁻²·sr⁻¹ or scaled DN) and apply documented scale factors; avoid double-scaling.\n- Per-year statistics: compute the mean intensity over valid_mask pixels for each year; also record the number of valid pixels. Optionally compute a robust mean (median or trimmed/winsorized mean) and compare to assess sensitivity to outliers.\n- Hotspot thresholding: set a per-year hotspot threshold at factor × that year’s mean (default factor = 1.5). Document the chosen factor and consider sensitivity tests (e.g., 1.25–2.0).\n- Hotspot proportion metric: compute the proportion of valid pixels exceeding the threshold for each year as ratio = count((NTL ≥ threshold_year) ∧ valid_mask) / count(valid_mask). State clearly whether reporting a fraction [0–1] or percent.\n- Inter-year change: report the difference in hotspot proportion between years (delta = proportion_year2 − proportion_year1). Optionally report percent change with an explicit epsilon guard to avoid inflated ratios when baselines are near zero.\n- Interpretation: map hotspots and their changes; interpret patterns (e.g., a slight increase suggests modest intensification of nighttime activity). Confirm water and known non-emissive areas remain excluded to avoid bias.\n- Sanity checks: inspect histograms and quick maps of NTL intensity, valid_mask, thresholds, and hotspot results; spot-check known bright/dim urban features (downtown, ports, industrial zones) for plausibility.\n- Reproducibility: explicitly log file paths, ROI definition, product/version, years, CRS/resampling choices, QA masks applied, threshold factor, outlier handling strategy, and software versions; write intermediate layers to disk for auditability.",
  "8": "Implement a reproducible, QC- and time-aware, area-aware split-window LST workflow for Band 31/32 sensors:\n- Inventory and verify inputs: programmatically list files and pass exact returned file paths; record sensor/platform (e.g., MODIS Terra/Aqua), thermal Bands 31/32 inputs (brightness temperature or radiance), units (Kelvin or radiance), scale factors, QA/cloud layers, land–water mask source, CRS/projection, pixel size, acquisition date/time, and the time standard (UTC vs local) used; include view/solar geometry if available, and the split-window coefficient set appropriate to the sensor/version; log tool/software versions.\n- AOI definition and clipping: define the analysis AOI (e.g., the exact urban ROI) and clip all rasters (Bands 31/32, emissivity, QA/cloud, land–water) to the AOI to keep computations bounded and reproducible.\n- Harmonize and co-register: ensure Bands 31 and 32, emissivity, and masks share the same CRS, resolution, and grid; reproject/resample as needed; verify alignment via overlay/spot checks and explicitly confirm that BT31/BT32 and emissivity are co-registered on the same pixel grid.\n- Units and BT preparation: confirm whether Bands 31/32 are provided as brightness temperatures in Kelvin. If only radiance is available, convert to brightness temperatures using the sensor’s Planck calibration (record constants and method) and avoid double-scaling.\n- Emissivity handling: obtain or derive emissivity needed for split-window (mean emissivity ε and band emissivity difference Δε = ε31 − ε32). Options: ingest a trusted emissivity product for the sensor/date; or derive from NDVI/land-cover using literature emissivity libraries. Document the source, units (dimensionless), and any assumptions.\n- Valid analysis mask: decode QA to exclude clouds, cloud shadows, snow/ice; apply a land–water mask to exclude water; remove NoData; combine into a single valid_mask used throughout. Compute all proportions strictly on valid land pixels (valid_mask).\n- Split-window LST: compute LST from T31 and T32 using the sensor-appropriate split-window formula and coefficients (e.g., LST = T31 + a·(T31 − T32) + b·(T31 − T32)^2 + c·(1 − ε) + d·Δε + optional view-angle/water-vapor terms if coefficients require them). Apply only on valid_mask; output LST in Kelvin and retain invalid pixels masked. Record the exact coefficient set and version/source.\n- Quick QC and scene selection: compute and log min/max and histograms of LST over valid_mask; generate quick-look maps of valid_mask and LST to confirm plausible ranges and spatial patterns. If outputs look implausible or do not match expectations/options (e.g., anomalous distributions, excessive artifacts, or unexpected spatial patterns), process all relevant overpasses within the analysis window, rerun the workflow with identical parameters, compare cloud/valid-pixel fractions and histogram shapes, and select the appropriate/best-quality scene. Document the selection rationale.\n- Area-aware hotspot proportion and differences: compute the proportion of valid land pixels with LST > 310 K using area-correct methods. Either reproject LST and valid_mask to an equal-area CRS (e.g., EPSG:6933) and use pixel counts, or compute per-pixel geodesic areas and weight: ratio = sum(area_i for i where (LST_i > 310 K ∧ valid_mask_i)) / sum(area_i for i where valid_mask_i). When comparing two scenes/dates, report the absolute percentage-point difference in hotspot proportion (delta_pp = 100 × (p2 − p1)) or clearly state if reporting as a fraction.\n- Reproducibility: explicitly log paths, AOI, projections/resampling choices, emissivity source, split-window coefficients, thresholds, dates/times with the UTC/local time convention, QA masks applied, scene/overpass selection criteria, and software versions; write intermediates (harmonized bands, masks, emissivity, LST, area weights) to disk for auditability.",
  "9": "Compute city-wide zonal totals with proper masking, area handling, and reproducible change metrics:\n- Inventory and verify inputs: programmatically list files and pass exact file paths; inspect and record metadata (units, CRS/projection, pixel size/resolution, scale factors, NoData/fill values, product/version) to ensure temporal comparability across years.\n- AOI definition and clipping: define the city boundary as the analysis region and clip all rasters to the AOI to keep computations bounded and consistent.\n- Harmonize grids: ensure all per-year rasters share the same CRS, resolution, and grid; reproject/resample as needed and verify alignment via overlay/spot checks.\n- Validity masking: decode and apply QA/cloud/water/NoData masks; explicitly exclude zeros used as NoData/fill so they do not bias totals; combine into a single valid_mask used throughout.\n- Units and scaling: confirm whether pixel values are absolute quantities (counts per pixel) or densities/intensities (per unit area); apply documented scale factors and avoid double-scaling; record units.\n- Area handling for densities: if values are densities (e.g., per m² or per km²), multiply each pixel’s value by its area to obtain per-pixel quantity. Compute area via an equal-area CRS (e.g., EPSG:6933) or geodesic per-pixel areas; document the method.\n- Zonal totals per year: compute the total over the AOI as the zonal sum across valid_mask pixels: total_year = sum(value_i × area_i for density products; else sum(value_i) for absolute-per-pixel products). Retain invalid pixels masked; log counts of valid pixels.\n- Change metrics: compute absolute change (Δ = total_year2 − total_year1) and percent change (%Δ = Δ / max(total_year1, epsilon) × 100). Use an explicit epsilon guard (e.g., 1e−6) to prevent division by zero; keep full precision for computations and apply consistent rounding only at reporting.\n- Sanity checks: inspect quick-look maps of valid_mask and per-pixel contributions; verify plausible ranges and that NoData/water/clouds are excluded; cross-check totals against spot calculations.\n- Reproducibility: explicitly log paths, AOI definition, projections/resampling choices, QA/nodata handling, area-calculation method, units/scale factors, years included/excluded, and software/tool versions; write intermediate layers (clipped rasters, valid_mask, area weights, per-pixel contributions) to disk for auditability.",
  "10": "Enforce a disciplined EO thermal city-level workflow scoped to the provided dataset and dates:\n- Discovery and filtering: programmatically list files from the specified path and filter strictly by the provided time window; record exact file paths, sensor/product, and tool versions to prevent timeframe/path mismatches.\n- Units/processing-level verification: verify Landsat Band 10 (or equivalent) units and processing level (brightness temperature vs LST). Confirm scale factors and Kelvin units; if needed, convert radiance to brightness temperature or harmonize BT/LST appropriately; avoid double-scaling.\n- AOI clipping and QA masking: clip each image to the city AOI. Decode QA/cloud/snow (and water where relevant) masks; remove NoData; combine into a single valid_mask used for all steps.\n- Harmonization checks: ensure rasters used for statistics share CRS, resolution, and grid within each city/date; snap/resample as needed and verify alignment via overlay checks.\n- Per-date spatial statistics: over valid_mask, compute robust area-averaged temperatures per date (e.g., mean plus median or a trimmed mean); log valid pixel counts to characterize coverage.\n- Cross-city date alignment: align dates across cities (use the intersection of clear, valid dates); optionally weight per-date statistics by valid pixel counts (or area) to account for differing coverage.\n- Temporal aggregation: compute city-level temporal means over the aligned dates using the chosen weighting; record which dates were included/excluded.\n- Unit conversion and comparison: convert aggregated temperatures from Kelvin to Celsius; compute the inter-city difference and report coverage (valid pixel counts/proportions) used in the aggregation.\n- Reproducibility: explicitly log paths, AOIs, time window, QA masks applied, units/conversions, weighting/aggregation choices, dates included, and software versions; write intermediates (valid masks and per-date stats) to disk for auditability.",
  "11": "Rigorously align MODIS LST+EVI to an agricultural AOI and compute TVDI dryness proportions with date-specific calibration over the Chengdu Plain:\n- Inventory and fetch exact-date inputs: programmatically list and record MODIS LST product (e.g., MOD11A1/MYD11A1 or MxD21), EVI (ingest MODIS EVI or compute from MODIS surface reflectance, e.g., MOD09/MYD09), and all QA layers. Log product names/versions, acquisition date/time, units (Kelvin or scaled), scale factors, CRS/projection, pixel size, and software/tool versions.\n- Units and scaling checks: confirm LST units are Kelvin and apply documented scale factors; for EVI, confirm whether values are scaled (e.g., int16 with scale) or computed from properly scaled red/NIR/blue reflectance; avoid double-scaling.\n- AOI definition and clipping: define the Chengdu Plain Agricultural Zone boundary; clip all rasters (LST, EVI/reflectance, QA/cloud, land–water) to this AOI to keep computations bounded and relevant.\n- Harmonize and co-register: ensure LST and EVI/reflectance share the same CRS, resolution, and grid; reproject/resample as needed; verify alignment via overlay checks and spot inspections.\n- Agricultural mask: ingest a vetted cropland/rice mask (e.g., ESA WorldCover, Copernicus Global Land Cover, or a rice distribution layer); reproject/resample to the MODIS grid; document class codes used and resampling method.\n- Valid analysis mask: decode MODIS QA to exclude clouds, poor-quality LST retrievals, cloud shadows, snow/ice; exclude water using a MODIS land–water mask or a conservative NDWI; remove NoData; combine with the cropland/rice mask to form a single valid_agri_mask used for all steps.\n- TVDI derivation with AOI/date-specific calibration: build the LST–EVI scatter over valid_agri_mask for the exact date; estimate wet and dry edges as functions of EVI; compute TVDI = (LST − LST_wet(EVI)) / (LST_dry(EVI) − LST_wet(EVI)); clip to [0, 1] and retain invalid pixels masked. Document the edge estimation method and parameters.\n- Dryness threshold metric: choose and document a dryness threshold (e.g., TVDI > 0.7). Compute the proportion over valid agricultural pixels as ratio = count((TVDI > threshold) ∧ valid_agri_mask) / count(valid_agri_mask). State clearly whether reporting a fraction [0–1] or percent. Optionally apply area weights if pixel areas vary (reproject to an equal-area CRS or use per-pixel geodesic areas).\n- Sanity checks: inspect histograms and quick-look maps of valid_agri_mask, LST, EVI, TVDI, and threshold results; verify plausible ranges for cropland; spot-check known paddy/rice areas for realism; confirm water/clouds remain excluded.\n- Reproducibility: explicitly log file paths, AOI definition, projections/resampling choices, MODIS product names/versions, dates/times, QA masks applied, cropland/rice mask source/version, TVDI edge calibration details, thresholds, and software versions; write intermediates (clipped/harmonized LST/EVI, masks, TVDI, threshold layers) to disk for auditability.",
  "12": "Locate and use the exact requested precipitation variable and run a disciplined monthly trend analysis:\n- Variable discovery and verification: programmatically enumerate files and read metadata to locate the exact requested precipitation variable/index (e.g., SPI, PDSI, or precipitation totals) for the specified window Sep–Dec 2021. Record product name, version, variable codes/names, units, scale factors, QA layers/flags, CRS, pixel size/resolution, and software/tool versions. Verify both the ROI and the months exist exactly as requested; do not substitute proxies like NDVI unless explicitly justified and documented.\n- ROI definition and clipping: define the correct analysis ROI and clip all rasters to it to bound computations. Harmonize grids so all month rasters share the same CRS, resolution, and pixel grid; reproject/resample as needed and verify alignment via overlay checks.\n- Validity masking: decode and apply QA/quality flags appropriate to the product to exclude low-quality/ephemeral/NoData pixels; combine with the ROI mask into a single valid_mask used throughout. Document the QA bits/thresholds applied.\n- Units and scaling: confirm and apply documented scale factors so values are in correct physical units (e.g., SPI/PDSI dimensionless, precipitation in mm). Avoid double-scaling and record the units used for analysis.\n- Monthly spatial means: for each month (Sep, Oct, Nov, Dec 2021), compute the spatial mean over valid_mask pixels within the ROI. Optionally compute robust metrics (median or trimmed mean) to assess sensitivity to outliers. Log valid pixel counts per month.\n- Period average: compute the Sep–Dec period average from the monthly spatial means; if valid coverage differs by month, weight the average by valid pixel counts (or area if pixel sizes vary). Record the weighting scheme and coverage used.\n- Time indexing and trend assessment: build an explicit time index for the four months (e.g., x = [2021-09, 2021-10, 2021-11, 2021-12] mapped to integers or days since a base date) and fit a linear regression on the monthly means. Report slope and R², and ensure intercept interpretability by documenting the chosen time index convention. Complement the parametric regression with the non-parametric Mann–Kendall test to assess monotonic trend significance; record p-value and test version/parameters.\n- Temporal completeness and guards: mark any missing months explicitly rather than assuming continuity; skip or flag the analysis if fewer than two months are available (insufficient for trend). Avoid implicit zeros; do not impute unless justified and documented.\n- Sanity checks: inspect histograms and quick-look maps of the variable per month and valid_mask; verify plausible ranges and spatial patterns for the region. Confirm QA masking removes known artifacts and that the ROI is correctly applied.\n- Reproducibility: explicitly log file paths, ROI definition, product/version, months included/excluded, CRS/resampling choices, QA masks/thresholds, scale factors/units, monthly means, weighting scheme, regression time index and results (slope, R²), Mann–Kendall test details (statistic, p-value), and software versions. Write intermediates (clipped rasters, valid_mask, monthly means) to disk for auditability.",
  "13": "Run a QC-aware ASTER TIR TTM-based urban LST/UHII workflow for Paris on 2020-06-28:\n- Inventory and scene selection: programmatically query/list ASTER TIR for 2020-06-28 (Terra ASTER L1B/L2). Record exact file paths, product/collection, TIR bands (10–12 minimum; note 10–14 if available), QA/cloud layers, geolocation, CRS, pixel size, radiometric units/scale factors, and acquisition date/time (UTC and local). Verify the overpass is available on the requested date; if not, select the nearest clear scene within a predefined window and log the deviation.\n- Units/calibration verification: confirm TIR inputs are radiance or brightness temperature. If radiance, convert to brightness temperature per band using the product’s Planck constants; avoid double-scaling. Keep temperatures in Kelvin throughout.\n- LST via the three-TIR-band method (TTM): compute LST from Bands 10–12 using a documented TTM implementation/coefficients appropriate for ASTER. Record the method/version, coefficients, and any emissivity assumptions or intermediate emissivity estimates. Output LST in Kelvin and write the LST to disk with a stable, explicit path; pass and log this exact TTM LST output path to subsequent steps.\n- AOI definition and clipping: use the Paris polygon as the analysis AOI; clip LST and QA/cloud layers to the AOI to bound computations.\n- Harmonize grids: ensure LST and QA/masks (and any ancillary layers) share the same CRS, resolution, and pixel grid; reproject/resample as needed; verify alignment with overlay checks.\n- Validity masking: decode/apply QA to exclude clouds, cloud shadows, snow/ice; exclude water via QA water flags or a conservative water mask derived from NDWI or a trusted land–water mask; remove NoData. Combine into a single valid_mask used in all steps. Document QA bits, NDWI thresholds (if used), and any land–water mask source/version.\n- Urban delineation (preferred, non-circular): build an urban_mask using authoritative land-cover sources (e.g., ESA WorldCover, GHSL, NLCD where applicable, OSM built-up). Reproject/resample the urban layer to the TTM LST grid and document class codes used and resampling method. If an authoritative layer is unavailable, derive an urban mask using combined indices (avoid NDVI-only proxies): for example, low NDVI AND high NDBI, with explicit thresholds (e.g., NDVI < 0.2–0.3 AND NDBI > 0.1–0.2). Document index computation (reflectance scaling), thresholds, and sensitivity checks.\n- Urban LST statistics (extremes and robustness): within valid_urban_mask = urban_mask ∧ valid_mask, compute (a) the true maximum LST and (b) a robust high percentile (e.g., 99.9th). Also compute supporting robust statistics (median, 95th) as needed. Clearly record the percentile parameter(s), the number/proportion of valid urban pixels, and the handling of masked/NaN values.\n- UHII (optional, with independent masks): to avoid circularity, compute UHII using independent masks rather than LST thresholds. Define urban_mask as above and define rural_mask from land-cover (e.g., cropland/grassland/natural) or outside the urban layer; reproject/resample and intersect with valid_mask. Compute mean (and optionally median) LST over each mask and UHII = mean(LST|urban_mask) − mean(LST|rural_mask) in Kelvin. Report valid pixel counts per mask. If LST-threshold-based masks must be used, log thresholds explicitly, warn about circularity, and perform a sensitivity check (e.g., ±2 K).\n- Time-of-day and context checks: confirm the acquisition is day vs night and note local time; interpret UHII and extreme statistics accordingly. Inspect quick-look maps/histograms of valid_mask, urban_mask, LST, and percentile/threshold outputs; verify plausible LST ranges and spatial patterns; confirm water remains excluded.\n- Reproducibility: log the exact TTM LST output path, AOI definition, product/version, date/time (UTC/local), calibration steps, TTM method/coefficients, QA/water masking approach (QA bits, NDWI thresholds or land–water mask source/version), urban delineation source/thresholds (land-cover class codes or NDVI+NDBI thresholds), percentiles computed, and software versions. Write intermediates (clipped LST, valid_mask, urban_mask, per-mask stats, percentile layers) to disk for auditability.",
  "14": "Derive and regress AOI-aggregated residential building volume time series (1985–2020) with explicit target construction, temporal subsetting, missing-year handling, and uncertainty:\n- Inventory and validate inputs: programmatically list built_volume_total and built_volume_nres files/columns; record units (e.g., m³), scale factors, product/version, and if gridded, CRS, pixel size, and NoData/fill values. Verify the two inputs cover the same years and are comparable (units/scales).\n- AOI and aggregation (for gridded inputs): define the Shanghai boundary (source/version) and clip rasters to it. Harmonize grids (CRS, resolution, pixel alignment); apply valid/NoData masks. Determine whether pixel values are absolute quantities or densities; if densities (per unit area), multiply by pixel area before summing. Aggregate each year’s built_volume_total and built_volume_nres to AOI totals; log valid pixel counts/areas.\n- Target metric derivation: compute residential_volume_year = built_volume_total_year − built_volume_nres_year. Enforce non-negativity checks and flag anomalies; confirm consistent units after subtraction and avoid double-scaling.\n- Temporal subsetting and indexing: strictly subset the time series to 1985–2020 inclusive. Build an explicit year index; sort and record any missing years rather than assuming continuity.\n- Missing-year handling: choose and document a strategy. Options: (a) drop missing years and fit on available years; list excluded years; or (b) interpolate (e.g., linear) only within the 1985–2020 range; flag imputed values and avoid extrapolation beyond the range. Justify the choice.\n- Regression setup and interpretability: construct regression x-values explicitly (year, or year − base_year so the intercept equals the residential volume at base_year). Use only the years retained after subsetting/handling missing values; document which entries were imputed if used.\n- Fit OLS and report uncertainty: fit an ordinary least squares regression residential_volume ~ year using Statsmodels (preferred for standard errors, confidence intervals, p-values, R²) or Scikit-learn (slope/intercept and R²; derive CIs via bootstrapping if needed). Report slope (change per year, in volume units/year), intercept (interpretable per chosen x convention), R², and confidence intervals where possible.\n- QC and diagnostics: visualize the time series with the fitted line; inspect residuals for trends/outliers/heteroskedasticity; consider robust regression if outliers dominate; verify no negative residential volumes after derivation. Ensure that unit magnitudes are plausible and consistent across years.\n- Reproducibility: log file paths, AOI definition, aggregation method and area handling, units/scale factors, years included/excluded, missing-year strategy, x-value convention/base year, regression library and version, and final metrics (slope, intercept, R², CIs). Write intermediates (AOI-aggregated yearly totals and the residential_volume series) to disk for auditability.\n- Implementation notes: use Pandas/NumPy for preprocessing and time indexing; GeoPandas and rasterstats (or equivalent) for AOI aggregation if inputs are gridded; Statsmodels or Scikit-learn for regression. Align with time-axis best practices so intercept meaning is explicit.",
  "15": "Implement a disciplined ATI workflow with day/night BT–albedo pairing, equal-area weighting, monthly aggregation, and burn cross-checks:\n- Inventory and verify inputs: programmatically list and record day and night thermal brightness temperature products (e.g., MODIS/VIIRS/TIRS BT in Kelvin), surface albedo (units and scale factors), QA/cloud/smoke layers, land–ocean mask, CRS/projection, pixel size, acquisition dates/times (UTC/local), and software/tool versions. Build explicit same-day (or within a defined tolerance) day/night pairs per date and log the pairing.\n- AOI definition and equal-area handling: define the analysis AOI and clip all rasters (day BT, night BT, albedo, QA/masks) to it. For area-weighted statistics, either reproject to an equal-area CRS (e.g., EPSG:6933) before aggregation or compute per-pixel geodesic areas; document the chosen method.\n- Harmonize and co-register: ensure day BT, night BT, albedo, and masks share the same CRS, resolution, and pixel grid; snap/resample as needed. Verify alignment via overlay checks so per-pixel pairing is exact.\n- Validity masking: decode and apply QA to exclude clouds, cloud shadows, smoke/aerosol-contaminated pixels (use product-specific flags), and water/ocean (via land–ocean mask). Require pixels to be valid in both day and night observations for a date pair. Remove NoData. Combine into a single valid_mask used in all steps; document QA bits/thresholds.\n- Units and scaling checks: confirm BT are in Kelvin; apply any radiance→BT conversions if needed and avoid double-scaling. Confirm albedo units (dimensionless [0–1] or scaled) and apply documented scale factors; clip albedo to [0, 1] if appropriate.\n- ATI formulation and computation: verify and document the ATI definition to be used (e.g., ATI ∝ (1 − albedo) / (T_day − T_night), or a literature/product-specific normalized variant). Record constants/normalizations and references. Compute ATI per pixel only within valid_mask; retain invalid pixels masked.\n- Threshold metric (ATI < 0.4 example): compute the area-weighted proportion of valid land pixels with ATI below the threshold. ratio = sum(area_i for i where (ATI_i < 0.4 ∧ valid_mask_i)) / sum(area_i for i where valid_mask_i). State clearly whether reporting a fraction [0–1] or percent, and log the threshold value and direction.\n- Per-date outputs and logging: for each paired date, compute and store ATI summaries (count/area of valid pixels, mean/median ATI, threshold proportion). Keep exact date/time and valid area per date.\n- Monthly aggregation options (document choice):\n  • Per-pixel temporal summary: compute a per-pixel monthly ATI (e.g., median across all valid dates in the month), then compute the monthly area-weighted proportion ATI < threshold over the monthly ATI layer.\n  • Area-weighted daily averaging: compute the daily area-weighted ATI<threshold proportion per date, then average across dates in the month weighted by each date’s valid area.\n- Cross-checks with independent burn indicators: validate ATI patterns against independent products such as MODIS/VIIRS active fire detections (e.g., VNP14/MOD14), burned area (e.g., MCD64A1), and/or smoke/aerosol layers. Document agreement/discrepancies and any decision rules.\n- Sanity checks: inspect histograms and maps of day/night BT, albedo, ATI, valid_mask, and threshold results per date and for monthly products; verify plausible ranges and spatial patterns; spot-check known recently burned or unburned areas.\n- Reproducibility: explicitly log file paths, AOI, projection/resampling choices, day–night pairing rules/tolerances, QA masks applied (codes/thresholds), ATI formula/reference and threshold, area-weighting method, per-date and monthly aggregation choices, dates/times (UTC/local), and software versions. Write intermediates (clipped/harmonized rasters, masks, per-date ATI, monthly ATI, area weights) to disk for auditability.",
  "16": "QC-aware NDWI-based Dead Sea water-loss analysis with baseline anchoring and per-date logs:\n- Inventory and verify inputs: programmatically list and record surface reflectance images and QA/cloud-shadow layers for the chosen sensor/time window (e.g., Landsat or Sentinel-2). Confirm required bands (Green, NIR; optionally SWIR1 for MNDWI), radiometric scale factors, units, CRS, pixel size, acquisition dates, and tool/software versions. Pass exact file paths between steps.\n- AOI definition and clipping: define a Dead Sea water-body AOI that covers the historical maximum extent (baseline water polygon or a buffered union) to include shoreline retreat areas. Clip all bands and QA layers to this AOI before index computation to keep work bounded and consistent.\n- Harmonize across dates: ensure all per-date rasters (reflectance bands, QA masks) share the same CRS, resolution, and pixel grid. Reproject/resample as needed; verify alignment via overlay checks and lock in a reference grid for all outputs.\n- Validity masking per date: decode QA/cloud-shadow/snow (and high aerosol if available) to create valid_mask_date; remove NoData. Use only valid pixels in all index calculations and thresholds.\n- NDWI/MNDWI computation: compute NDWI = (Green − NIR) / (Green + NIR) on valid pixels (or MNDWI = (Green − SWIR1) / (Green + SWIR1) if preferred for turbid/saline water). Confirm reflectance scale factors and avoid double-scaling. Document the chosen index and formula.\n- Baseline water mask: select a clearly cloud-free date (or a short-window composite, e.g., max NDWI/min SWIR) to create a trusted baseline water mask. Derive threshold via a validated fixed value (e.g., NDWI ≥ 0) or AOI-derived Otsu threshold on valid pixels; apply light morphology (opening/closing) and remove tiny components. Persist the baseline mask on the reference grid and log the baseline date(s) and threshold used.\n- Per-date thresholding: for each date, choose a thresholding strategy and document it: fixed validated threshold or AOI-derived Otsu computed from that date’s valid NDWI histogram. Record the threshold value per date and the method.\n- Water classification per date: classify water_mask_date = (NDWI ≥ threshold_date) ∧ valid_mask_date (or MNDWI variant). Keep invalid pixels masked.\n- Loss metric (baseline-anchored): compute the water-loss proportion relative to the baseline using only pixels that are valid on that date to avoid cloud bias:\n  • denominator_date = count(baseline_water_mask ∧ valid_mask_date)\n  • numerator_date = count(baseline_water_mask ∧ ¬water_mask_date ∧ valid_mask_date)\n  • loss_fraction_date = numerator_date / max(denominator_date, 1)\n  State clearly whether reporting as fraction [0–1] or percent. Set and log a minimum coverage guard (e.g., require denominator_date ≥ 50% of baseline water pixels); flag dates below the guard as uncertain.\n- Area-aware option: if pixel areas vary (multi-sensor or latitude-spanning AOI), use equal-area handling: either reproject to an equal-area CRS (e.g., EPSG:6933) and count pixels, or compute per-pixel geodesic areas and weight the numerator/denominator by area.\n- Date-to-metric logs and alignment: maintain an explicit, sorted date-to-metric table with columns: date/time, file paths, index (NDWI/MNDWI), threshold method/value, valid counts (denominator/numerator), loss_fraction (and percent), coverage guard status. Persist this table to disk to prevent time misalignment.\n- QC and sanity checks: inspect NDWI/MNDWI histograms, quick-look maps of valid_mask, baseline mask, per-date water masks, and loss results; spot-check known retreat zones. Verify plausible dynamics (loss should not be negative; unexpected gains warrant review). Document any threshold sensitivity checks.\n- Reproducibility: log AOI definition, projections/resampling, QA bit rules, index formulas, baseline selection and thresholds, coverage guard, dates included/excluded, and software versions. Write intermediates (clipped reflectance, valid masks, NDWI/MNDWI, baseline mask, per-date water masks) to disk for auditability.",
  "17": "Define the peak metric and run a QC-aware MODIS window/absorption band-ratio workflow for coastal Guangdong:\n- Clarify and document the peak definition up front: decide whether \"peak\" means (a) pixel-level maximum across the period, (b) AOI-mean peak day, or (c) a robust percentile-based peak. Recommended: robust percentile peak = max over days of the AOI’s daily 95th percentile (P95). State the choice explicitly in outputs.\n- Inventory and verify inputs: programmatically list MODIS Terra/Aqua products and exact files; record product names/collections (e.g., MOD021KM/MYD021KM L1B radiance with MOD35 cloud mask, or MOD09/MYD09 Surface Reflectance with state_1km QA), targeted bands (window: B02 and/or B05; absorption: B17–B19), acquisition dates/times (UTC/local), units (radiance vs reflectance), scale factors, QA/cloud/cirrus/shadow layers, sunglint flags (from ocean-color L2 if used) or geometry needed to derive glint angle, land/sea mask source, CRS, pixel size, and software/tool versions.\n- AOI definition and clipping: use the exact coastal Guangdong polygon; clip all bands and QA/masks to this AOI to bound processing.\n- Harmonize and co-register: ensure all bands and masks share the same CRS, resolution, and pixel grid; reproject/resample as needed; verify alignment via overlay checks.\n- Units and scaling: confirm each band’s units and scale factors; convert to a consistent domain (e.g., TOA reflectance) before computing ratios; avoid double-scaling. Note and document any BRDF/geometry effects; optionally restrict to acceptable view/sun-zenith ranges to stabilize ratios.\n- Valid analysis mask: decode and apply MODIS QA to exclude clouds, cloud shadow, cirrus, and NoData; apply a sunglint mask (use product glint flag if available or threshold by computed glint angle); optionally restrict to water/nearshore if the target is marine absorption. Combine into a single valid_mask used in all steps.\n- Band-ratio computation (validated formula): compute the window/absorption ratio consistently over valid_mask, e.g., ratio = ρ_window / mean(ρ_B17, ρ_B18, ρ_B19), with ρ_window = ρ_B02 or ρ_B05 (choose and document). Keep invalid pixels masked; log the exact formula and bands used.\n- Daily clear-sky composites: for each day, aggregate multiple passes/sensors into a daily composite using a robust statistic (median or trimmed mean) over valid observations; record the per-pixel observation count per day.\n- Peak extraction per chosen metric:\n  • Pixel-level peak: take the per-pixel max of the daily composite ratio across the period; summarize AOI stats (mean/median/P95 of the per-pixel peaks).\n  • AOI-mean peak: compute the AOI mean (and robust alternative) of the daily composite ratio per day; the peak is the maximum daily AOI mean across the period.\n  • Robust percentile peak (recommended): compute the AOI daily P95 over valid_mask; the period peak is max(daily P95). Record the percentile and any trimming used.\n- Sanity checks: inspect daily histograms/maps of the ratio, valid_mask, and observation counts; verify expected ranges and spatial patterns; cross-check the period peak against a regional climatology/seasonal baseline for coastal Guangdong. Flag and diagnose peaks coinciding with low valid coverage, high glint risk, or unit mismatches.\n- Reporting: clearly state the peak metric definition, bands/formula, units, the peak value and date, valid coverage (pixel count/area), and any view/glint thresholds applied. Include sensitivity notes if both B02 and B05 window bands were tested.\n- Reproducibility: log exact file paths, AOI definition, products/versions, dates/times, CRS/resampling choices, QA and glint masking rules, ratio formula and band set, compositing statistic, peak metric/percentile, and software versions; write intermediates (clipped bands, valid_mask, per-day composites, daily AOI stats) to disk for auditability."
}